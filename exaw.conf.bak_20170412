#### Logstash Conf for Exaw IoStat
#### Author   Date
#### ===================
#### dongwkim 2017/04/11

input {
    beats {
        port => "5044"
    } 
    file {
        path => "/var/log/archive/*Iostat*.dat"
        start_position => "beginning"
    }
}

filter {

    if [message] !~ /^(Time|sd[a-z][^0-9]|nvme|Linux)/ {
        drop { }
    }
    mutate {
        add_field => { "taskId" => "IoStat" }
    }
    multiline {
        pattern => "^Time"
        negate => "true"
        what => "previous"
    }
    grok {
        patterns_dir => "./patterns"
        match => { "message" => "Linux%{SPACE}%{GREEDYDATA:kernel}%{SPACE}\(%{GREEDYDATA:hostname}\)%{SPACE}%{DATE_US:logday}" }
        tag_on_failure => ["data_line"]
    }
    ruby {
        code => "event.set('message',event.get('message').split(/\n/))"
    }

    if "data_line" not in [tags] {
        aggregate {
            task_id => "%{taskId}"
            code => "map['logday'] = event.get('logday')"
        }
        aggregate {
            task_id => "%{taskId}"
            code => "map['hostname'] = event.get('hostname')"
        }
        drop { }
    }
    else {
        grok {
            patterns_dir => "./patterns"
            match => { "message" => "Time: %{GREEDYDATA:logtime}" }
        }
        grok {
            patterns_dir => "./patterns"
            match => { "message" => "sd[a-l]%{SPACE}%{BASE10NUM:rrqm_s}%{SPACE}%{BASE10NUM:wrqm_s}%{SPACE}%{BASE10NUM:r_s}%{SPACE}%{BASE10NUM:w_s}%{SPACE}%{BASE10NUM:rsec_s}%{SPACE}%{BASE10NUM:wsec_s}%{SPACE}%{BASE10NUM:avgrq_sz}%{SPACE}%{BASE10NUM:avgqu_sz}%{SPACE}%{BASE10NUM:await}%{SPACE}%{BASE10NUM:svctm}%{SPACE}%{BASE10NUM:util}" }
        }
        grok {
            patterns_dir => "./patterns"
            match => { "message" => "sd([n-z]|a[a-c])%{SPACE}%{BASE10NUM:f_rrqm_s}%{SPACE}%{BASE10NUM:f_wrqm_s}%{SPACE}%{BASE10NUM:f_r_s}%{SPACE}%{BASE10NUM:f_w_s}%{SPACE}%{BASE10NUM:f_rsec_s}%{SPACE}%{BASE10NUM:f_wsec_s}%{SPACE}%{BASE10NUM:f_avgrq_sz}%{SPACE}%{BASE10NUM:f_avgqu_sz}%{SPACE}%{BASE10NUM:f_await}%{SPACE}%{BASE10NUM:f_svctm}%{SPACE}%{BASE10NUM:f_util}" }
        }
        aggregate {
            task_id => "%{taskId}"
            code =>  "event.set('logday', map['logday'])"
            map_action => "update"
        }
        aggregate {
            task_id => "%{taskId}"
            code => "event.set('hostname', map['hostname'])" 
            map_action => "update"
        }
        mutate {
            convert => { "rrqm_s" => "float" }
            convert => { "wrqm_s" => "float" }
            convert => { "r_s" => "float" }
            convert => { "w_s" => "float" }
            convert => { "rsec_s" => "float" }
            convert => { "wsec_s" => "float" }
            convert => { "avgrq_sz" => "float" }
            convert => { "avgqu_sz" => "float" }
            convert => { "await" => "float" }
            convert => { "svctm" => "float" }
            convert => { "util" => "float" }
            convert => { "f_rrqm_s" => "float" }
            convert => { "f_wrqm_s" => "float" }
            convert => { "f_r_s" => "float" }
            convert => { "f_w_s" => "float" }
            convert => { "f_rsec_s" => "float" }
            convert => { "f_wsec_s" => "float" }
            convert => { "f_avgrq_sz" => "float" }
            convert => { "f_avgqu_sz" => "float" }
            convert => { "f_await" => "float" }
            convert => { "f_svctm" => "float" }
            convert => { "f_util" => "float" }
            add_field => { "timestamp" => "%{logday} %{logtime} +0900" }
        }
    }
    date {
        match => [ "timestamp","MM/dd/yyyy hh:mm:ss a Z" ]
        target => "@timestamp"
    }
}

output {
    elasticsearch {
        hosts => [ "localhost" ]
         manage_template => false
#        index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
         index => "iostat-%{+YYYY.MM.dd}"
         document_type => "%{[@metadata][type]}"
#        index => "logstash-%{+YYYY.MM.dd}"
    }
#    stdout { codec => rubydebug }
}
